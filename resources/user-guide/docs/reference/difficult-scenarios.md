# Difficult Calibration Scenarios

Calibration gets uncomfortable. You'll face moments where someone in the room has power to protect a rating, where fear overrides honesty, or where nobody wants to say what everyone knows. These scenarios document the hard moments and give you concrete language to navigate them.

## Who Should Read This

**For facilitators:** Scripts and tactics for handling the most challenging calibration moments.

**For participants:** Understand what to do when calibration gets difficult.

**For leaders:** See what actually happens in calibration rooms and how to create better outcomes.

---

## The Protected Pet

### Situation

A senior leader has a direct report who is clearly underperforming. Everyone in the room knows this person is "protected" - maybe they're friends outside work, maybe they hired them and don't want to admit the mistake, maybe there's history nobody talks about.

The senior leader presents their ratings. When they get to this person, they rate them as High Performer. The evidence doesn't support it. Everyone else in the room sees the disconnect.

Nobody says anything. The room gets quiet. The inflated rating stands unchallenged.

### What Goes Wrong If Unaddressed

**The immediate damage:**
- Everyone else in the room loses trust in the process
- Managers who rated honestly feel like suckers
- The actual high performers get devalued (if that person is a High Performer, what does High Performer even mean?)
- The underperforming employee doesn't get honest feedback they need to improve

**The long-term damage:**
- Calibration becomes theater where politics matter more than evidence
- Good managers stop preparing or caring because the outcome is predetermined
- The best managers start looking for organizations that actually value honest assessment
- The protected employee continues underperforming, everyone knows it, nobody addresses it

### Facilitator Response

This is your hardest job as a facilitator. You have to make the conversation happen without creating a confrontation.

**Gentle approach - name what you're seeing:**

> "I notice we moved quickly past this one. Let's spend a moment here. [Senior leader], can you share the specific achievements or behaviors that led to the High Performance rating?"

This isn't accusatory. You're just asking for evidence, which should be standard for every rating.

**If they provide vague evidence:**

> "That's helpful context. Let me ask the group - when we compare this to the other High Performers we've discussed today, how does the evidence stack up? Are we seeing the same level of impact and outcomes?"

You've made it a group discussion, not you versus the senior leader.

**If the room stays silent:**

> "I'm sensing some hesitation. This is exactly the kind of moment where calibration adds value - when we can respectfully compare our perspectives. What are we seeing that might be different?"

**If you need to be more direct:**

> "I want to make sure we're applying the same bar to everyone. For other High Performers today, we've seen [specific examples]. For this person, I'm hearing [what they said]. Let's talk about whether those are comparable."

### Follow-Up and Outcome

**Best case:** The senior leader hears the gap in evidence and revises the rating, or provides compelling evidence nobody else knew about that justifies the rating.

**Common case:** The senior leader holds firm, but you've created a record that the rating was challenged. The silence has been broken. Other participants see that you'll surface difficult conversations.

**After the meeting:** If the inflated rating stands despite clear evidence to the contrary, this is a conversation for whoever commissioned the calibration (HR leader, CEO, board). The facilitator's job is to surface the issue, not to overrule a senior leader in the room.

**Note for next time:** If this pattern repeats, the facilitator should talk to the senior leader one-on-one before calibration: "I've noticed your team's ratings tend to be higher than peers. Let's talk about what High Performance means for your group compared to the broader organization."

---

## Recency Bias Problem

### Situation

An employee had a terrible Q1, weak Q2, disappointing Q3, but knocked it out of the park in Q4 with a high-visibility project. Their manager wants to rate them as High Performer based on recent memory.

When you ask about the full year, the manager says "But they really turned it around" or "That Q4 project was exceptional."

### What Goes Wrong If Unaddressed

**The accuracy problem:**
- The rating doesn't reflect actual performance over the full period
- You're rewarding trajectory (improving) but labeling it as sustained high performance
- Other employees who performed well all year get the same rating as someone who performed well for 25% of the year

**The fairness problem:**
- Managers who rated based on the full period feel undermined
- Employees who had consistent high performance all year feel devalued
- You're teaching managers that only recent performance matters, which encourages gaming the system

### Facilitator Response

**Acknowledge the positive trajectory:**

> "It's great that they had a strong Q4. That shows real growth and capability. The question for calibration is: does one strong quarter after three weak quarters equal sustained High Performance, or does it equal 'improving Medium Performer'?"

**Frame it as full-period assessment:**

> "Calibration should account for the full performance period, not just recent memory. A strong finish after a weak start is meaningful - it suggests potential and trajectory. But for this rating, we're assessing the full year. Based on the complete picture, where does this person land?"

**Offer a path forward:**

> "Here's what I'm hearing: Q1-Q3 were struggles, Q4 was excellent. That's not High Performance for the full period - that's improvement. I'd recommend Medium Performance with a note that they're trending up strongly. That's accurate and fair, and it sets them up to earn High Performance next period if they sustain this level."

**If the manager pushes back:**

> "Let me ask the group: if someone performs at High level for one quarter out of four, does that equal the same rating as someone who performed at High level for all four quarters? What's the threshold for sustained versus episodic high performance?"

### Follow-Up and Outcome

**Most likely outcome:** The manager agrees to Medium Performance with notes about strong Q4 trajectory. This is accurate and fair.

**Alternative approach:** Rate them High Performance but add a note: "Rating based heavily on exceptional Q4. Performance earlier in year was below High bar - watch for sustained performance at this level."

**After calibration:** The manager should have a conversation with the employee: "Your Q4 was outstanding - exactly what High Performance looks like. Q1-Q3 didn't meet that bar. Let's talk about what it takes to sustain Q4 level performance all year. Do that, and you'll be a clear High Performer next period."

**The key:** Distinguish between "improving" and "sustained high performance." Both are valuable, but they're different things.

---

## The New Manager

### Situation

A first-time manager is in their first calibration. They've never calibrated their understanding of "High Performance" against peers. They rated everyone on their team High because they genuinely think their team is great - they've never seen what "great" looks like at this company.

When you compare their ratings to other managers, it's immediately obvious they're rating 2-3 levels too generously.

### What Goes Wrong If Unaddressed

**For the manager:**
- They'll be embarrassed when the gap becomes obvious
- They might get defensive to protect their ego
- They lose credibility with peers
- They learn that calibration is about fighting, not learning

**For their team:**
- Employees get inflated ratings that don't reflect organizational standards
- When those ratings get adjusted down in calibration, employees feel the manager didn't advocate for them
- The team's actual high performers get lost in the grade inflation

### Facilitator Response

**Frame it as a learning experience from the start:**

> "For anyone who's new to management or new to this organization, your first calibration is a learning experience. You're going to hear how your ratings compare to others, and you might discover your bar is different from the organizational standard. That's completely normal - that's what calibration is for. Don't get defensive; get curious."

**When the pattern becomes obvious:**

> "[Manager], I'm noticing your ratings trend higher than others in the room. This is really common for new managers - you're comparing your team to your own expectations, but calibration is about comparing to the organizational bar. Let's walk through a few examples together so you can see the difference."

**Compare specific examples side by side:**

> "You've rated Alex as High Performance. [Other manager] rated Jamie as Medium Performance. Let's look at what each person delivered this year. Alex did [list]. Jamie did [list]. Based on what we're seeing, do these feel like the same level of performance?"

This makes the gap concrete without attacking the manager's judgment.

**Give them a graceful way to adjust:**

> "Now that you've heard how others are calibrating, how are you thinking about your ratings? It's completely fine to revise them - that's the whole point of this conversation."

### Follow-Up and Outcome

**Best case:** The new manager sees the gap, recalibrates their understanding, and adjusts their ratings. They leave calibration with a clearer picture of organizational standards.

**After calibration:** The facilitator or the manager's own leader should debrief with them:

> "That was a learning experience. Here's what I saw: your instinct is to rate generously, which comes from a good place - you want to support your people. In this organization, High Performance means [specific criteria]. Medium Performance isn't an insult - it means meeting expectations. Let's talk about how to apply that lens going forward."

**Next time:** The manager comes prepared with examples and has already calibrated their thinking against organizational standards. They're a better manager because of it.

**The key:** Make this about learning and development, not embarrassment. First calibration should be a clarifying experience, not a punishing one.

---

## The Layoff Shadow

### Situation

Everyone knows layoffs are coming or might be coming. Managers are afraid to rate anyone as Low Performance because they think it creates "a list." They'd rather inflate ratings to protect their people.

The result: Nobody gets rated Low, even people who genuinely are underperforming. The center box swells with everyone rated Medium/Medium to be "safe."

### What Goes Wrong If Unaddressed

**The irony:**
- By distorting ratings to protect people, managers corrupt the data leaders use to make decisions
- Leaders can't trust calibration data, so they make layoff decisions based on other criteria (headcount ratios, politics, recency bias)
- The actual low performers don't get honest feedback that could help them improve
- High performers get devalued because everyone's rated the same

**The trust damage:**
- Employees eventually figure out that ratings are fiction
- Good managers who rated honestly feel betrayed
- Calibration loses all credibility as a process
- Next time, everyone inflates ratings because that's what worked

**The protection paradox:**
- When you can't differentiate high from low performers, you can't protect your high performers
- The whole point of calibration is to identify who to keep - if everyone's the same rating, nobody's protected

### Facilitator Response

**Name the elephant directly:**

> "I want to address what might be in the room. If there are concerns about how calibration data will be used, let's talk about that now. The purpose of calibration is to get an accurate picture of our talent. If we distort ratings out of fear, we make worse outcomes more likely, not less."

**Explain why honest ratings are protective:**

> "Here's the paradox: if you distort ratings to 'protect' people from imaginary lists, you corrupt the data that leaders use to make decisions. Ironically, this makes it harder to identify and retain your best people. Honest calibration is actually more protective in the long run because it helps the organization see who's essential."

**Address the fear directly:**

> "Calibration should reflect reality, not fear. If someone is genuinely a Low Performer, rating them Medium doesn't help them - it denies them the feedback they need to improve. If someone is genuinely a High Performer, they need to be rated that way so the organization knows to keep them."

**If managers push back:**

> "I understand the concern. But consider this: if we calibrate honestly, leaders have accurate data about who's delivering and who's not. If we inflate ratings, leaders can't trust calibration at all, and they'll make decisions based on less reliable information. Which scenario better protects your people?"

### Follow-Up and Outcome

**If the fear is legitimate (layoffs are definitely coming):**

The facilitator should escalate to whoever commissioned the calibration:

> "Managers are afraid to rate honestly because they think it creates a target list. If that's true, we need to address it. If it's not true, we need to communicate that clearly. Either way, we can't do accurate calibration when fear overrides honesty."

**If the fear is speculative:**

After addressing it in the room, continue with normal calibration. Most managers will recalibrate once the fear is named and addressed.

**After calibration:**

Leaders should communicate clearly how calibration data will and won't be used. Transparency builds trust.

**The key:** Fear-based rating distortion makes everyone less safe, not more. Honesty is protective.

---

## The Exit Already Planned

### Situation

An employee is being managed out, has been put on a performance improvement plan, or has already resigned. Their manager wants to rate them Low to justify the exit or rationalize the decision.

The problem: their actual performance during the rating period might have been Medium or even High. The manager is retroactively adjusting the rating to match the narrative.

### What Goes Wrong If Unaddressed

**Data integrity:**
- The calibration data becomes unreliable because it's been manipulated
- You can't learn from historical data if ratings were changed to justify exits
- Future calibrations can't reference past ratings as baselines

**Trust erosion:**
- Other managers see that ratings can be manipulated to support HR actions
- It signals that calibration is about justifying decisions, not making accurate assessments
- Managers learn to distort ratings to match desired outcomes

**Unfairness:**
- The employee's actual performance during the period doesn't get recorded accurately
- If they performed well but didn't fit culturally, that's different from poor performance
- Inaccurate ratings create problems if the employee later applies for another role internally

### Facilitator Response

**State the principle:**

> "We rate performance as it actually was during the assessment period, not retroactively to justify exits. If someone was a solid performer who didn't fit culturally, that's different from poor performance. The rating should reflect reality."

**Ask about the full period:**

> "Let's talk about the full performance period we're calibrating. Before [the PIP / the resignation / the decision], what level was this person performing at? That's the rating, regardless of what happened after."

**If the manager insists the performance was always low:**

> "Help me understand the timeline. If performance was Low, when did that start? What specific examples demonstrate Low Performance during the full rating period?"

If the evidence supports Low Performance, rate it Low. If the evidence doesn't support it, don't distort the rating.

**If they're conflating performance with fit:**

> "It sounds like there might be two different issues: performance (what they delivered) and fit (cultural alignment, values, team dynamics). Those should be tracked separately. Someone can be a Medium Performer who isn't the right fit. That's a legitimate reason for an exit, but it doesn't mean we rate their performance lower than it was."

### Follow-Up and Outcome

**Most likely outcome:** The manager agrees to rate performance accurately with a note about cultural fit or other factors that led to the separation.

**The rating should reflect:** What the person actually delivered during the period, not the decision to exit them.

**After calibration:** Document clearly why someone who performed at Medium or High level was exited. That's valuable organizational learning: "We had someone who hit their numbers but couldn't collaborate - here's what we learned."

**The key:** Don't retroactively distort ratings to justify exits. Dishonest ratings - even for people leaving - undermine trust in the entire system.

---

## Manager Wants Team-Only Review

### Situation

A manager says "Can we just look at my team?" or "I'd like to calibrate my people as a group."

This sounds reasonable - they want to focus on their people. The problem: it defeats the entire purpose of calibration.

### What Goes Wrong If Unaddressed

**The calibration failure:**
- When you only look at one team, you can't compare standards across teams
- Manager A's "High Performer" might not equal Manager B's "High Performer"
- You can't identify if a manager is rating too high or too low relative to peers
- Silos get reinforced instead of broken down

**The missed value:**
- Calibration's value comes from cross-team comparison
- You identify organizational patterns (grade inflation, undervaluing certain roles, etc.)
- You can't develop consistent standards if each team calibrates in isolation

**What actually happens:**
- Every manager ends up with their own definition of High Performance
- Employees in different parts of the organization get rated on different scales
- Promotion and compensation decisions become unfair because ratings aren't comparable

### Facilitator Response

**Redirect to level-based calibration:**

> "I understand the impulse to focus on your team, but that actually defeats the purpose of calibration. The value comes from comparing across teams to ensure consistent standards. Instead of team-by-team, we're going to calibrate level-by-level: all Senior Engineers together, all Engineering Managers together, etc."

**Explain why:**

> "When we calibrate all Senior Engineers together - yours, [Manager B's], and [Manager C's] - we can see if the bar is consistent. That's how we catch patterns like grade inflation or undervaluing certain work. If we calibrate each team separately, we miss that."

**Offer the alternative:**

> "You'll still get to discuss your people - but you'll discuss your Senior Engineers alongside everyone else's Senior Engineers. That's actually better for your team because it ensures they're being rated fairly against organizational standards, not just your standards."

**If they push back:**

> "Let me ask: what's your goal? If it's to review your team's distribution, we can do that with filters during calibration. If it's to ensure your people are rated fairly, the best way to do that is to calibrate them against peers at the same level across the organization."

### Follow-Up and Outcome

**Most likely outcome:** The manager understands and participates in level-based calibration.

**If they still resist:** This might indicate they know their ratings don't match organizational standards and they're trying to avoid the comparison. Address that directly:

> "I'm sensing some hesitation about cross-team comparison. Is there a concern about how your team's ratings will compare to others? If so, let's talk about that - calibration is exactly where we work through those differences."

**After calibration:** If you do discover that one manager's standards are different, that's a coaching conversation: "Your ratings trend higher than peers. Let's talk about what High Performance means organizationally versus how you've been thinking about it."

**The key:** Team-only review is not calibration. Calibration requires comparison across teams to establish consistent standards.

---

## Everyone is Medium/Medium

### Situation

You're calibrating a cohort and 70% of the employees are in the center box (Medium Performance, Medium Potential). The distribution looks like a bullseye - huge center, thin edges.

This usually means managers are avoiding differentiation. It's easier to put everyone in the middle than to make hard calls about who's actually high or low.

### What Goes Wrong If Unaddressed

**The avoidance problem:**
- Managers aren't doing the hard work of differentiation
- Employees who are genuinely high performers get lumped with average performers
- Employees who are struggling don't get identified for support or intervention
- The organization can't make good decisions about promotions, development, or succession

**The fairness problem:**
- It's unfair to actual high performers to rate them the same as average performers
- It's unfair to struggling performers to not give them honest feedback
- You're prioritizing manager comfort over employee development

**The data problem:**
- Calibration data becomes useless for decision-making
- Leaders can't identify talent, flight risks, or development needs
- The whole exercise becomes theater

### Facilitator Response

**Name the pattern:**

> "I'm noticing a pattern. About 70% of this cohort is in the center box. That usually means we're avoiding differentiation. Let's talk about why."

**Use forced-choice questioning:**

> "Let's try something. If you had to promote one person from this center group tomorrow - critical role, needs to be filled immediately - who would you pick?"

This forces differentiation. Whoever they pick probably isn't Medium/Medium.

**Ask the inverse:**

> "Now the harder question: if you had to let one person from this center group go due to budget cuts, who would it be?"

Whoever they pick probably isn't Medium/Medium either.

**Surface the actual differences:**

> "You just identified two people in the same box who you'd treat very differently in high-stakes decisions. That tells me they're not actually the same rating. Let's place them accurately."

**Challenge the clustering:**

> "In most organizations, truly Medium/Medium is about 40-50% of the population. We're at 70%. That usually means one of two things: either your group is genuinely less differentiated than most organizations (possible but rare), or we're avoiding making distinctions. Which is it?"

### Follow-Up and Outcome

**The forced-choice technique works because:**
- It makes abstract ratings concrete
- Managers know the differences between their people - they just haven't articulated them as ratings
- High-stakes scenarios (promotions, exits) force honest differentiation

**After using this technique:**
- Some center-box people move to High Performance / High Potential
- Some move to Medium Performance / Low Potential or vice versa
- The distribution becomes more realistic

**If managers still resist:**

> "Let me be clear: Medium/Medium isn't an insult. It means meeting expectations with standard growth trajectory. That describes a lot of people. But if someone is genuinely a high performer or a high potential, we need to name that. And if someone is struggling, they need to know that too. Clustering everyone in the middle helps nobody."

**The key:** Force concrete differentiation through high-stakes hypotheticals. Most managers know who's better than whom - they just need permission to say it.

---

## The Absent Vote

### Situation

A manager can't attend calibration - they're traveling, they're sick, they have a conflicting commitment. Their team needs to be calibrated, but their advocate isn't in the room.

### What Goes Wrong If Unaddressed

**The representation problem:**
- Nobody speaks for this manager's people
- They might get rated lower than they should because nobody advocates
- Context that only the manager knows doesn't get shared
- Employees get short-changed through no fault of their own

**The fairness problem:**
- Employees with advocates in the room get better representation
- Employees whose manager is absent get worse outcomes
- This creates arbitrary unfairness

### Facilitator Response

**Option 1: Reschedule (preferred)**

> "[Manager] can't attend today. Their team deserves to have their manager in the room advocating for them. Let's reschedule this cohort for a time when everyone can attend."

**Option 2: Proxy (if rescheduling impossible)**

> "Since [Manager] can't be here, we need someone who can speak to their team's performance. [Manager's manager] or [peer who works closely with the team], can you represent these employees today?"

The proxy should:
- Have direct knowledge of the employees' work
- Have talked to the absent manager about their ratings beforehand
- Be empowered to advocate and adjust ratings

**Option 3: Defer (if no good proxy available)**

> "We don't have enough context to calibrate [Manager's] team fairly today. We'll hold those employees and calibrate them when [Manager] can attend."

### Follow-Up and Outcome

**After calibration:**

If you used a proxy, the absent manager should review the outcomes:
- Do they agree with the final ratings?
- Was any context missed that changes the calibration?
- Do any ratings need to be revisited?

**The principle:**

Every employee deserves to have their manager in the room or an informed proxy who can advocate for them. Calibrating without representation leads to arbitrary bad outcomes.

**The key:** When a manager can't attend, reschedule or proxy - don't calibrate their people without representation.

---

## The "Everyone Knows" Problem

### Situation

Everyone in the room knows someone is underperforming. It's obvious. Their work is weak, they miss deadlines, they create more problems than they solve.

Their manager presents their rating: Medium Performance.

The room goes silent. Nobody wants to be the one to say it.

### What Goes Wrong If Unaddressed

**The immediate damage:**
- The obvious truth doesn't get spoken
- The underperformer doesn't get identified for support or intervention
- Everyone else loses trust in the process ("Why did we bother if we can't even name the obvious?")

**The long-term damage:**
- The underperformer continues underperforming
- Their team members bear the burden of covering for them
- The manager doesn't have to have the hard conversation
- Calibration becomes polite fiction instead of honest assessment

### Facilitator Response

**If you're in calibration and you're thinking "everyone knows this person is struggling, but no one is saying it," say it.**

**Direct approach:**

> "I'm going to name what I think is in the room. Based on what I've heard about this person's work, it sounds like they're struggling. Multiple people have mentioned [missed deadlines / quality issues / team friction]. That doesn't sound like Medium Performance to me. Let's talk about it."

**Invitation approach:**

> "I notice we got quiet on this one. That usually means something's difficult. If you're thinking something different than Medium Performance, now's the time to say it."

**Evidence-based approach:**

> "Help me square something. For other Medium Performers today, we've seen [examples of solid work]. For this person, I'm hearing [examples of struggles]. Those don't sound equivalent. What am I missing?"

**The courage to name the obvious is what makes calibration valuable.**

### Follow-Up and Outcome

**Most likely outcome:**

Once someone names it, others confirm it. The rating gets adjusted to Low Performance. The manager now has organizational backing to have the hard conversation with the employee.

**After calibration:**

The manager should talk to the employee:
> "In calibration, it became clear your performance isn't meeting expectations. Here are the specific gaps: [list]. Let's talk about what support you need and what improvement looks like."

**If nobody speaks up even after facilitator prompting:**

This is a psychological safety problem bigger than this one employee. After calibration, the facilitator should debrief with leadership:
> "We had obvious underperformance that nobody would name. That's a culture issue. People don't feel safe telling the truth in calibration, which means we're not getting value from the process."

**The key:** If you stay quiet to be polite, you're failing the organization AND the employee (who isn't getting honest feedback they need).

---

## The Unknown Gem

### Situation

During calibration, someone mentions an employee casually. A peer manager says "Wait, tell me more about them." As the conversation unfolds, it becomes clear this person is exceptional - they've been delivering high-impact work, mentoring others, driving key initiatives.

But their manager rated them Medium Performance. The manager seems surprised when peers highlight the person's contributions.

### What Goes Wrong If Unaddressed

**The talent loss risk:**
- Great employee is invisible to leadership
- They don't get promoted or recognized
- They eventually leave for an organization that sees their value
- You lose high performers through neglect

**The manager development gap:**
- Manager doesn't recognize their best people
- They might not be giving this person challenging work
- They're not advocating effectively
- This is a coaching opportunity being missed

### Facilitator Response

**When the pattern emerges:**

> "This is interesting. [Manager], you rated this person as Medium Performance, but I'm hearing from [peer managers] that they've been driving [high-impact work]. Tell me more about what you're seeing."

**Surface the gap:**

> "Here's what I'm noticing: [Peer A] mentioned this person led the X initiative. [Peer B] said they mentored the new hires. [Peer C] highlighted their work on Y project. That sounds like more than Medium Performance. How are you thinking about this?"

**Make it a learning moment, not an attack:**

> "This is actually really valuable - calibration sometimes reveals talent that's been overlooked. It sounds like this person might be a stronger performer than their current rating reflects. What would it take to move them to High Performance?"

### Follow-Up and Outcome

**Most likely outcome:**

The manager realizes they've been undervaluing this person. The rating gets adjusted to High Performance.

**The coaching conversation after calibration:**

The facilitator or the manager's own leader should talk to them:

> "In calibration, your peers recognized [Employee's] contributions before you did. That's worth reflecting on. How can you make sure you're seeing your team's strongest work? Are you checking in enough? Are you aware of cross-functional impact?"

**The conversation with the employee:**

The manager should tell them:

> "I want to share something from calibration. Your work on [projects] came up, and it was clear you're delivering at a High Performance level. I should have recognized that sooner. Let's talk about how to keep that momentum and what opportunities we can create for you."

**The key:** Calibration can reveal talent that's been overlooked. That's a feature, not a bug - it's a chance to course-correct and recognize strong performers who weren't getting visibility.

---

## The Recalibration Moment

### Situation

You're halfway through calibration. You've rated the first few cohorts (Individual Contributors, then Senior ICs, then Managers). You're now looking at the Director cohort.

Someone says: "Wait. Looking at these Directors compared to the Managers we just rated... I think we were too generous with the Managers. These Directors are clearly stronger, but we rated half the Managers as High Performers too."

The group realizes the standards have been drifting across cohorts.

### What Goes Wrong If Unaddressed

**The inconsistency problem:**
- Different cohorts get rated on different standards within the same session
- Later cohorts get rated more harshly (or more leniently) than earlier ones
- The final distribution is inaccurate

**The fairness problem:**
- People rated early in the session get different treatment than people rated late
- This is arbitrary and unfair

### Facilitator Response

**Embrace the recalibration:**

> "This is a really good observation. Looking at the Directors, I think you're right - we might have been too lenient with the Managers. Here's what I want to do: let's finish the Directors, and then we'll go back and revisit the Managers with fresh eyes."

**Normalize it:**

> "This happens. As we see more examples, our sense of the bar gets refined. It's intellectually honest to say 'we need to revisit earlier decisions with what we know now.' That's calibration working as intended."

**Go back and recalibrate:**

After finishing Directors, return to the Manager cohort:

> "Now that we've seen the full range, let's look at the Managers again. Who did we rate High that, in hindsight, should be Medium? We're not changing our minds randomly - we're applying the consistent standard we've now established."

### Follow-Up and Outcome

**This requires intellectual honesty:**
- Admitting earlier decisions were off
- Being willing to revisit and revise
- Accepting that calibration is iterative, not perfect on first pass

**The outcome:**
- More consistent ratings across cohorts
- Better calibration overall
- Managers in the room learn that flexibility and revision are signs of good judgment, not weakness

**After calibration:**

Document the recalibration in notes:
> "Initial rating was High, revised to Medium after calibrating Directors cohort and realizing earlier standards were too lenient."

**The key:** If you're halfway through calibration and realize earlier cohorts were off, say so. It's okay to go back. Pretending earlier decisions were perfect produces worse outcomes than honest recalibration.

---

## Unresolved Disagreement

### Situation

Two managers fundamentally disagree about an employee's rating after thorough discussion. One says High Performance, the other says Medium. You've heard the evidence, asked clarifying questions, and the group is split.

Neither side is budging. The disagreement is genuine - not political, not defensive, just different interpretations of the same evidence.

The clock is ticking. You have 15 more people to calibrate.

### What Goes Wrong If Unaddressed

**The session derails:**
- One disagreement consumes 30 minutes while 15 people wait
- Other important calibrations get rushed or skipped
- Participants lose focus and energy

**The relationship damage:**
- Managers dig in and it becomes personal
- The disagreement escalates beyond this one employee
- Future calibration discussions become harder

**The decision paralysis:**
- You can't move forward, can't move back
- The session ends without resolution
- Nobody knows what the final rating is

### Facilitator Response

**First, acknowledge the disagreement respectfully:**

> "I'm hearing two thoughtful perspectives here. [Manager A] sees High Performance based on [their evidence]. [Manager B] sees Medium Performance based on [their evidence]. Both views have merit."

**Then, name the constraint:**

> "We've spent 15 minutes on this discussion, and we have 15 more people to calibrate. We need to make a decision and move forward. Here are three options."

**Option 1: Manager's rating stands**

Use when: The employee's direct manager has better context than others in the room.

> "This is [Manager A's] direct report. They have the most direct visibility into day-to-day performance. Unless we have strong evidence to override them, I'm inclined to go with [Manager A's] rating of High Performance. We'll document the dissenting view and can revisit in the next calibration if needed."

**Option 2: Facilitator decides**

Use when: You have enough context to make the call and both perspectives have been heard.

> "I've heard both sides. Based on what we've discussed and comparing to the standards we've applied to similar employees today, I'm going to call this Medium Performance. [Manager A], I know you see it differently - let's add a note that this was a close call and worth revisiting next period."

**Option 3: Table and escalate**

Use when: The disagreement reveals a deeper issue about standards or the decision has high stakes.

> "This disagreement is revealing something important about how we define High Performance in [this context]. Rather than forcing a decision right now, let's table this one. I'll work with [Manager A] and [Manager B] offline to align on standards, and we'll finalize this rating after the session. For now, let's move on."

### Follow-Up and Outcome

**Document the disagreement:**

Add a note to the employee record:
> "Calibration discussion: Rating debated between High and Medium. [Manager A] cited [evidence for High]. [Manager B] cited [evidence for Medium]. Final rating: [X]. Revisit in next calibration cycle."

**After the session:**

If you used Option 1 or 2, follow up with the dissenting manager:
> "I know you saw that employee differently. Help me understand what I might have missed. Let's make sure we're aligned on standards going forward."

If you used Option 3, schedule a follow-up within 48 hours:
> "Let's get [Manager A], [Manager B], and me in a room to resolve this. We'll review the evidence, agree on what High Performance means in this context, and finalize the rating."

**The key principle:**

Don't let one disagreement consume your entire session. It's better to make an imperfect decision and move forward than to let perfect be the enemy of good.

**When to invest more time:**

Spend extra time on disagreements when:
- The disagreement reveals unclear organizational standards (this is worth resolving)
- The employee is high-stakes (succession candidate, performance improvement case)
- The pattern repeats across multiple employees (systemic issue)

**When to move on quickly:**

Use time limits when:
- The disagreement is genuine but not systemic (reasonable people differ)
- The stakes are medium (solid performer, not critical role)
- You've already spent 10+ minutes discussing it

**Facilitator language for moving on:**

> "I appreciate the thorough discussion. We're not going to reach consensus in the next five minutes, so here's what we're going to do: [State decision]. If new evidence emerges, we can revisit. For now, let's move forward."

**The key:** Your job is to facilitate good decisions in reasonable time, not to achieve perfect consensus on every employee. Sometimes "good enough with a note" is the right answer.

---

## Back to the Guide

These scenarios are part of the complete calibration documentation:

- Back to [Complete Calibration Guide](../best-practices.md)
- Back to [Getting Started with Calibration](../getting-started.md)
- Related: [Creating Psychological Safety](psychological-safety.md)
- Related: [Power Dynamics and Politics](power-dynamics-and-politics.md)
- Related: [Post-Calibration Conversations](post-calibration-conversations.md)

---

**Final Thought:** The difficult scenarios are where calibration earns its value. Anyone can calibrate easy cases. The hard moments - protected pets, layoff fears, obvious underperformance nobody will name - are where facilitation skill and organizational courage matter most.
