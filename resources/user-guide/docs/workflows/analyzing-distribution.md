# Analyzing Your Talent Distribution

> **Time to complete:** 15-20 minutes
> **When to use this:** Before calibration meetings, quarterly talent reviews, or when assessing overall workforce health
> **You'll need:** Employee data uploaded to 9Boxer

Understanding how your talent is distributed across the 9-box grid is critical for succession planning, identifying calibration issues, and making strategic talent decisions. This workflow shows you how to analyze your distribution, interpret what you find, and take action based on the insights.

---

## Distribution Analysis Checklist

Use this comprehensive checklist to systematically analyze your talent distribution and identify issues requiring attention.

### Before You Start

- [ ] Have employee data uploaded to 9Boxer
- [ ] Understand your organization's target distribution benchmarks
- [ ] Know the context (preparing for calibration, quarterly review, board presentation)
- [ ] Allow 15-20 minutes for complete analysis

### Review Overall Distribution

- [ ] Open Statistics tab and review distribution table
- [ ] Compare percentages to healthy benchmarks (10-15% Stars, 40-50% Core)
- [ ] Identify which boxes are over-populated or under-populated
- [ ] Note percentage in center box (Position 5) - flag if >60%
- [ ] Check if top talent percentage (Stars) is sufficient for succession planning
- [ ] Review visual bar chart for immediate pattern recognition

### Check Intelligence for Anomalies

- [ ] Open Intelligence tab and review Quality Score
- [ ] Note if score is below 75 (indicates calibration issues)
- [ ] Review all red anomalies (critical issues requiring immediate attention)
- [ ] Review all yellow anomalies (moderate issues worth investigating)
- [ ] Identify patterns by manager, department, location, or level
- [ ] Document specific anomalies to investigate further

### Drill into Problem Areas

- [ ] Use Filters to isolate flagged managers or departments
- [ ] Compare filtered distribution to overall distribution
- [ ] Identify specific employees who may need recalibration
- [ ] Test different filter combinations (manager, performance level, department)
- [ ] Take notes on specific employees or groups to discuss in calibration
- [ ] Gather evidence to support or refute Intelligence anomalies

### Document Findings

- [ ] Summarize key distribution issues identified
- [ ] List specific anomalies with expected vs. actual counts
- [ ] Create discussion topics for calibration meeting
- [ ] Prepare action items with owners and deadlines
- [ ] Set target distribution percentages to aim for
- [ ] Note which managers or departments need calibration training

### Prepare for Action

- [ ] Create prioritized list of employees to review in calibration
- [ ] Prepare specific questions for managers about flagged patterns
- [ ] Consider using Donut Mode to validate center box (Position 5)
- [ ] Schedule calibration meeting if significant issues found
- [ ] Export pre-calibration baseline for comparison later
- [ ] Share preliminary findings with calibration meeting attendees

### For Executive Presentations (Optional)

- [ ] Create executive summary with overall assessment and quality score
- [ ] Highlight key metrics (Stars %, High Potential Pipeline %, Core %)
- [ ] Summarize critical issues in 3-5 bullet points
- [ ] Prepare recommended actions with timeline and accountability
- [ ] Define target outcomes (quality score, distribution percentages)
- [ ] Take screenshots of Statistics and Intelligence tabs for visual support

### After Analysis

- [ ] Verify you can answer: What percentage in each position?
- [ ] Verify you can answer: How does distribution compare to benchmarks?
- [ ] Verify you can answer: What anomalies or biases exist?
- [ ] Verify you can answer: Which managers/departments need calibration?
- [ ] Verify you can answer: What specific actions will improve distribution?
- [ ] Verify you can answer: Is succession pipeline healthy (enough Stars)?

---

## When to Use This Workflow

Use this distribution analysis workflow when you need to:

- **Prepare for talent reviews** - Understand overall distribution before discussing individual employees
- **Assess succession pipeline health** - Check if you have enough high-potential employees for future leadership roles
- **Identify calibration issues** - Spot grade inflation, harsh raters, or inconsistent standards across teams
- **Present to executives or board** - Create data-driven insights about workforce quality
- **Track changes over time** - Compare this quarter's distribution to previous quarters
- **Validate hiring strategy** - Ensure new hires improve your talent distribution

---

## Scenario: Sarah's Quarterly Talent Review Preparation

Sarah is an HR Director preparing for the quarterly talent review meeting with her CEO. She has 180 employees across 4 departments. Before the meeting, she needs to assess distribution health, identify any issues, and prepare discussion topics.

Let's follow Sarah's workflow.

---

## Step 1: Review Overall Distribution (5 minutes)

Start by getting the big picture of your talent distribution.

### Open Statistics Tab

1. Load your employee data (or use sample data to practice)
2. Click anywhere on the grid (or click outside employee tiles)
3. Click the **Statistics** tab in the right panel

You'll see the distribution table showing count and percentage for each of the 9 boxes.

![Statistics panel showing distribution table and visual chart](../images/screenshots/statistics/statistics-panel-distribution.png)

### Interpret the Distribution Table

Look at the percentages in each box and compare to healthy benchmarks:

**Healthy Distribution Benchmarks:**

| Position | Benchmark | What It Means |
|----------|-----------|---------------|
| Stars (Position 9 - High/High) | 10-15% | Your top talent ready for advancement |
| High Potential Row (Positions 7, 8, 9) | 20-30% | Future leadership pipeline |
| Core Talent (Position 5 - Medium/Medium) | 40-50% | Solid, reliable performers |
| Under-performers (Positions 1, 2, 3) | 10-20% | Need development or performance management |

### What Sarah Sees

Sarah reviews her distribution:

- Stars (Position 9): 8% (14 employees) - Slightly low
- High Potential row: 18% (32 employees) - Within range
- Core Talent (Position 5): 62% (111 employees) - Too high (clustering)
- Under-performers: 5% (9 employees) - Reasonable

**Sarah's Initial Observations:**

- Too many employees in center box (62% vs. target 40-50%)
- Slightly low Stars percentage (8% vs. target 10-15%)
- This suggests poor differentiation - are some "Core Talent" actually stars or under-performers?

### Success! You've Reviewed Distribution

You'll see:
- Distribution table with counts and percentages
- Visual bar chart showing patterns
- Specific red flags like center box clustering
- Data to compare against healthy benchmarks

!!! note "Why This Matters"
    Distribution analysis reveals whether your ratings are balanced or biased. If 60% are in the center box, you know calibration needs to focus on differentiation. This prevents grade inflation before it impacts promotions or retention.

You'll see:

- Distribution table with counts and percentages for all 9 boxes
- Visual bar chart showing relative population of each box
- Immediate pattern recognition (which boxes are over/under-populated)
- Summary cards showing totals and averages

---

## Step 2: Use Intelligence to Spot Anomalies (5 minutes)

Now let's see if Intelligence detected any patterns or biases that might explain the distribution.

### Open Intelligence Tab

1. Click the **Intelligence** tab in the right panel
2. Review the Quality Score at the top
3. Scroll down to see Anomaly Cards

![Intelligence panel showing detected bias patterns](../images/screenshots/workflow/intelligence-summary-anomalies.png)

### Interpret the Quality Score

Check the overall data quality score:

| Score Range | What It Means | Action Needed |
|-------------|---------------|---------------|
| 90-100 | Excellent - well calibrated | No action needed |
| 75-89 | Good - minor issues only | Monitor trends |
| 60-74 | Fair - review recommended | Schedule calibration |
| 40-59 | Poor - significant issues | Immediate calibration needed |
| 0-39 | Critical - severe bias | Pause and recalibrate before finalizing |

### Review Anomaly Cards

Look for red (critical) or yellow (moderate) anomalies:

**Common Anomaly Types:**

- **Manager Leniency/Harshness** - One manager rates significantly higher/lower than peers
- **Department Bias** - One function has skewed distribution (e.g., Sales rated higher than Engineering)
- **Location Bias** - One office rates differently than others
- **Level Bias** - Managers rated higher than individual contributors
- **Tenure Bias** - New hires over-rated, veterans under-rated

### What Sarah Sees

Sarah's Intelligence tab shows:

- Quality Score: 68 (Fair - Review Recommended)
- Red Anomaly: "Manager Alex Chen - Leniency Bias"
  - Expected: 3 employees High Performance
  - Actual: 15 employees High Performance (400% deviation)
- Yellow Anomaly: "Engineering Department - Central Tendency"
  - 85% of Engineering in Position 5 (Core Talent)
  - Expected: 50% in Position 5

**Sarah's Takeaways:**

- Manager Alex needs calibration discussion (rating too high)
- Engineering manager may be avoiding differentiation (everyone rated "Medium")
- These patterns partially explain the center box clustering

### ✅ Success! You've Identified Anomalies

You'll see:

- Quality score indicating overall rating health
- Color-coded anomaly cards (red = critical, yellow = moderate, green = minor)
- Expected vs. actual employee counts showing statistical deviations
- Specific managers, departments, or locations flagged for review

---

## Step 3: Drill into Problem Areas with Filters (5 minutes)

Now use filters to investigate the issues you identified.

### Investigate Manager Leniency

1. Click the **Filters** button in the toolbar
2. Under **Manager**, select **"Alex Chen"**
3. Review the filtered grid showing only Alex's team

You'll see:

- Grid showing only Alex's 20 direct reports
- Orange dot on Filters button (filters active)
- Employee count: "20 of 180 employees"

**Questions to Ask:**

- Are the employees in "High Performance" truly exceptional?
- How do they compare to similar employees rated by other managers?
- Is this a genuinely high-performing team, or is Alex too lenient?

### Investigate Department Clustering

1. Clear the Manager filter
2. Under **Function**, select **"Engineering"**
3. Review Engineering department distribution

**What to Look For:**

- Are there employees in Position 5 who might be Stars but rated conservatively?
- Are there employees who belong in under-performer boxes?
- Is the Engineering manager avoiding difficult performance conversations?

### Compare Across Departments

Try filtering different departments to compare:

- Engineering vs. Sales vs. Marketing
- Do some departments have more differentiation?
- Are rating standards consistent across functions?

### What Sarah Discovers

After filtering:

**Alex's Team:**

- 15 of 20 rated "High Performance"
- When compared to similar job levels in other teams, only 5 appear truly "High"
- 10 employees should be rated "Medium Performance"
- Alex needs recalibration training

**Engineering Department:**

- 60 employees total, 51 in Position 5 (85%)
- Sarah identifies 8 employees who demonstrate high potential (leadership, mentoring, innovation)
- 6 employees who are actually under-performing (missing deadlines, quality issues)
- Engineering manager needs to differentiate more

### ✅ Success! You've Drilled into Problem Areas

You'll see:

- Filtered view showing only the problematic group
- Ability to compare individuals within that group
- Evidence to support or refute anomalies flagged by Intelligence
- Specific employees who may need recalibration

---

## Step 4: Document Your Findings (3 minutes)

Create notes summarizing what you found for the upcoming calibration meeting.

### Prepare Discussion Topics

Based on your analysis, document:

**Key Findings:**

1. **Overall Distribution Issue:** 62% in center box - too much clustering
2. **Manager Leniency:** Alex Chen rating 15/20 as High Performance
3. **Department Issue:** Engineering showing extreme central tendency (85% in Position 5)
4. **Succession Risk:** Only 8% Stars - need to identify and develop more top talent

**Recommended Actions:**

1. Hold calibration session with Alex Chen's manager to review his team
2. Work with Engineering manager to differentiate performance levels
3. Use Donut Mode to validate Position 5 employees (identify hidden Stars and under-performers)
4. Target: Reduce Position 5 to 45%, increase Stars to 12%, maintain proper differentiation

### Create Action Items

For the calibration meeting:

- [ ] Review Alex Chen's team with his manager - recalibrate 10 employees
- [ ] Review Engineering Position 5 employees - identify 8 high-potential, 6 under-performers
- [ ] Use Donut Mode exercise with leadership team to validate center box
- [ ] Re-check Statistics after calibration to verify improved distribution
- [ ] Track quality score improvement (target: 75+)

### ✅ Success! You've Documented Findings

You'll have:

- Clear summary of distribution issues identified
- Specific anomalies flagged with evidence (expected vs. actual counts)
- Action items for calibration meeting
- Target distribution percentages to aim for

---

## Step 5: Present Insights to Leadership (Optional)

If you're presenting to executives or the board, create a summary of your findings.

### Executive Summary Template

**Talent Distribution Health: Quarterly Review [Q4 2024]**

**Overall Assessment:** Fair (Quality Score: 68/100)

**Key Metrics:**

- Total Employees: 180
- Stars (Top Talent): 14 (8%) - Below target of 10-15%
- High Potential Pipeline: 32 (18%) - Within range
- Core Performers: 111 (62%) - Above target, indicates clustering

**Critical Issues Identified:**

1. **Manager Calibration:** 1 manager showing severe leniency bias (15/20 rated High)
2. **Department Differentiation:** Engineering showing 85% central tendency
3. **Succession Risk:** Insufficient Stars percentage for leadership pipeline

**Recommended Actions:**

1. Hold cross-functional calibration sessions (target completion: January 15)
2. Manager training on rating standards (target: 2 managers)
3. Re-assess using Donut Mode to validate center box (target: reduce to 45%)

**Target Outcomes:**

- Quality Score: 75+ (Good)
- Stars: 12-15% (succession planning healthy)
- Core Talent: 40-50% (proper differentiation)

### ✅ Success! You've Created Executive Summary

You'll have:

- One-page summary suitable for executive/board presentation
- Data-driven insights (not subjective opinions)
- Clear metrics showing current state vs. targets
- Action plan with timeline and accountability

---

## What Success Looks Like

You've successfully analyzed your distribution when you can answer:

- ✅ What percentage of employees are in each grid position?
- ✅ How does your distribution compare to healthy benchmarks?
- ✅ What anomalies or biases exist in your ratings?
- ✅ Which managers or departments need calibration?
- ✅ What specific actions will improve your distribution?
- ✅ What does your succession pipeline look like (enough Stars)?

---

## Common Mistakes to Avoid

!!! warning "Don't Accept Surface-Level Distribution"
    Seeing "62% in Position 5" isn't enough. Ask WHY. Is it genuine? Or is it managers avoiding differentiation?

!!! warning "Don't Ignore Intelligence Warnings"
    Red anomalies indicate <1% chance the pattern is random. Take them seriously - they almost always reveal real issues.

!!! warning "Don't Compare Without Context"
    "Sales has more Stars than Engineering" might be justified (different talent pools) or bias (different rating standards). Investigate before concluding.

!!! warning "Don't Skip Manager Conversations"
    If Intelligence flags a manager, don't just recalibrate their ratings without discussing. They may have legitimate reasons (genuinely exceptional team) or need training.

!!! warning "Don't Forget to Re-Check After Changes"
    After recalibrating employees, return to Statistics to verify distribution improved. Track quality score improvement over time.

---

## Tips from Experienced Users

**Start with Intelligence, Not Statistics**

> "I used to dive into Statistics first, but now I start with Intelligence. The quality score tells me immediately if I have work to do. If it's 90+, I do a quick Statistics review. If it's <75, I know I need to investigate anomalies before finalizing ratings." - Rachel, HR Director

**Use Filters to Prepare Evidence**

> "When Intelligence flags a manager, I filter to their team before the calibration meeting. I take screenshots comparing their team to peers. Having visual evidence makes the conversation easier." - James, Talent Lead

**Track Distribution Quarterly**

> "We track our quality score and Stars percentage quarterly. Improving trends mean our calibration efforts are working. Declining scores mean we need to course-correct." - Priya, VP Talent

**Combine Statistics + Intelligence + Donut Mode**

> "My workflow: Statistics (identify clustering) → Intelligence (spot bias) → Filters (investigate) → Donut Mode (validate center box) → Re-check Statistics. This catches 95% of issues before finalizing ratings." - Sarah, HR Director

---

## Related Workflows

- [Talent Calibration Preparation](talent-calibration.md) - Use distribution analysis as input to calibration meetings
- [Making Rating Changes](making-changes.md) - Recalibrate employees based on distribution insights
- [Adding Notes & Documentation](adding-notes.md) - Document rationale for distribution-driven changes

---

## Related Features

- [Statistics and Intelligence](../statistics.md) - Complete guide to distribution analysis and anomaly detection
- [Filtering and Focus](../filters.md) - Advanced filtering strategies for investigation
- [Understanding the Grid](../understanding-grid.md) - What each position means strategically

---

## Need Help?

**Common Questions:**

**Q: What if my quality score is low but I believe my ratings are accurate?**

A: Low scores indicate statistical inconsistency, not necessarily wrong ratings. Investigate each anomaly - some may be justified (genuinely exceptional team) while others reveal bias. Document justifications for legitimate deviations.

**Q: How often should I analyze distribution?**

A: Minimum quarterly. Best practice: before every calibration session (typically 2-4 times per year). Track trends over time to ensure continuous improvement.

**Q: What if different departments have genuinely different talent levels?**

A: Document the justification. If Sales truly hires from top MBA programs while Operations promotes from within, different distributions may be legitimate. Intelligence flags statistical outliers - you decide if they're justified or bias.

**Q: Can I export distribution data for presentations?**

A: Yes! Take screenshots of Statistics and Intelligence tabs. The visual charts and tables are designed for executive presentations. You can also export to Excel and create custom charts.

---

**Ready to analyze your distribution?** [Load your data](../employee-data.md) or practice with [sample data in the quickstart](../quickstart.md).
