# Backend Refactoring Plan - Safe Sequencing Strategy

**Status:** ğŸ“‹ Active Plan
**Created:** 2026-01-05
**Milestone:** [backend-arch-review](https://github.com/bencan1a/9boxer/milestone/16)
**Estimated Duration:** 12-16 weeks

## Executive Summary

This document outlines a **safe, incremental refactoring strategy** for addressing 10 architectural issues identified in the backend code review. The plan sequences work to:

- **Minimize Risk**: Each phase is independently testable and deployable
- **Build Foundations First**: Critical infrastructure changes precede dependent refactorings
- **Enable Rollback**: Clear checkpoints allow reverting without data loss
- **Maintain Functionality**: System remains operational throughout refactoring

## Dependency Graph

Understanding dependencies is critical for safe sequencing:

```
Phase 1: Foundations (Weeks 1-4)
â”œâ”€â”€ #234: Dependency Injection â­ FOUNDATIONAL
â”‚   â””â”€â”€ Enables: #241, #237, #252
â”‚
â””â”€â”€ #255: Consolidate Constants
    â””â”€â”€ Enables: #254, #250

Phase 2: Data Access Layer (Weeks 5-8)
â”œâ”€â”€ #241: Repository Pattern (depends on #234)
â”‚   â””â”€â”€ Enables: #237, #252
â”‚
â””â”€â”€ #245: Excel Field Mapping (parallel)
    â””â”€â”€ Enables: #250

Phase 3: Service Layer Decomposition (Weeks 9-12)
â”œâ”€â”€ #237: Split SessionManager (depends on #234, #241)
â”‚   â””â”€â”€ Enables: #252
â”‚
â”œâ”€â”€ #252: Event Tracking (depends on #234, #237)
â”‚
â””â”€â”€ #256: Complex Export Method (parallel)

Phase 4: Standards & Configuration (Weeks 13-16)
â”œâ”€â”€ #253: Error Handling Standards (parallel)
â”‚
â”œâ”€â”€ #254: Configuration Management (depends on #255)
â”‚
â””â”€â”€ #250: Column Schema (depends on #245, #255)
```

## Phased Rollout Strategy

### **Phase 1: Foundations (Weeks 1-4)**
*Build the infrastructure everything else depends on*

#### **Week 1-2: #234 Dependency Injection** ğŸ”´ CRITICAL - BLOCKING
**Why First:** Every other refactoring depends on proper DI

**Approach: Strangler Fig Pattern**
```
Step 1 (Days 1-2): Create infrastructure
  â”œâ”€â”€ Create backend/dependencies.py
  â”œâ”€â”€ Define get_db_manager() factory
  â””â”€â”€ Add tests for DI system

Step 2 (Days 3-5): Migrate one API router (proof of concept)
  â”œâ”€â”€ Choose simple router (e.g., /health)
  â”œâ”€â”€ Add Depends() parameters
  â”œâ”€â”€ Test thoroughly
  â””â”€â”€ Deploy to dev environment

Step 3 (Days 6-8): Migrate remaining API routers
  â”œâ”€â”€ session.py
  â”œâ”€â”€ employees.py
  â”œâ”€â”€ statistics.py
  â””â”€â”€ intelligence.py
  âš ï¸ One router per day, test between each

Step 4 (Days 9-10): Remove global singleton
  â”œâ”€â”€ Delete db_manager global instance
  â”œâ”€â”€ Verify no imports remain
  â””â”€â”€ Update all tests to use fixtures
```

**Success Criteria:**
- âœ… All API endpoints use Depends() for database access
- âœ… Zero references to global `db_manager`
- âœ… All tests pass with isolated database fixtures
- âœ… No regression in functionality

**Rollback Plan:**
- Keep global `db_manager` until Step 4
- Can revert individual routers if issues found
- No database schema changes = safe rollback

**Testing Strategy:**
```python
# Before migrating each router
def test_router_before_migration():
    """Baseline: current behavior"""
    response = client.get("/endpoint")
    assert response.status_code == 200
    baseline_data = response.json()

# After migrating router
def test_router_after_migration():
    """Verify: identical behavior with DI"""
    response = client.get("/endpoint")
    assert response.status_code == 200
    assert response.json() == baseline_data
```

---

#### **Week 3-4: #255 Consolidate Constants** ğŸŸ¡ MEDIUM - NON-BLOCKING
**Why Early:** Enables #254 and #250, low risk

**Approach: Create Once, Migrate Incrementally**
```
Step 1 (Days 1-2): Create constants module
  â”œâ”€â”€ Create backend/constants.py
  â”œâ”€â”€ Define EmployeeField, BoxPosition, EventType enums
  â”œâ”€â”€ Add LOCAL_USER_ID, system constants
  â””â”€â”€ Create comprehensive tests

Step 2 (Days 3-5): Find all duplicates
  â”œâ”€â”€ grep -r "local-user" backend/
  â”œâ”€â”€ grep -r "top_right" backend/
  â”œâ”€â”€ Document all locations
  â””â”€â”€ Create migration checklist

Step 3 (Days 6-8): Replace duplicates systematically
  â”œâ”€â”€ Replace in models/ (1 day)
  â”œâ”€â”€ Replace in services/ (2 days)
  â”œâ”€â”€ Replace in api/ (1 day)
  â””â”€â”€ Update tests (1 day)

Step 4 (Days 9-10): Cleanup and validation
  â”œâ”€â”€ Remove all old constant definitions
  â”œâ”€â”€ Add linting rule to prevent duplicates
  â””â”€â”€ Generate TypeScript enums (future work)
```

**Success Criteria:**
- âœ… Single source of truth for all constants
- âœ… All duplicate definitions removed
- âœ… Enums used for type safety
- âœ… No behavior changes

**Rollback Plan:**
- Constants module is additive only
- Can keep old constants until fully migrated
- No data or behavior changes

---

### **Phase 2: Data Access Layer (Weeks 5-8)**
*Separate data access from business logic*

#### **Week 5-6: #241 Repository Pattern** ğŸ”´ CRITICAL - DEPENDS ON #234
**Why Second:** Enables clean service layer refactoring

**Approach: One Repository at a Time**
```
Step 1 (Days 1-2): Repository infrastructure
  â”œâ”€â”€ Create backend/repositories/ directory
  â”œâ”€â”€ Create BaseRepository abstract class
  â”œâ”€â”€ Add repository integration test fixtures
  â””â”€â”€ Document repository pattern

Step 2 (Days 3-4): EmployeeRepository (first/simplest)
  â”œâ”€â”€ Create EmployeeRepository class
  â”œâ”€â”€ Implement CRUD operations
  â”œâ”€â”€ Add find_by_session_and_box()
  â”œâ”€â”€ Add get_box_distribution()
  â””â”€â”€ Integration tests with real DB

Step 3 (Days 5-6): SessionRepository
  â”œâ”€â”€ Create SessionRepository class
  â”œâ”€â”€ Extract all session queries
  â””â”€â”€ Integration tests

Step 4 (Days 7-8): Update services to use repositories
  â”œâ”€â”€ Add repository dependencies to services
  â”œâ”€â”€ Replace direct SQL with repository calls
  â””â”€â”€ Update service tests to mock repositories

Step 5 (Days 9-10): EventRepository and cleanup
  â”œâ”€â”€ Create EventRepository
  â”œâ”€â”€ Remove all SQL from service layer
  â””â”€â”€ Verify no direct database access remains
```

**Success Criteria:**
- âœ… Zero SQL queries in service layer
- âœ… All data access through repositories
- âœ… Services testable with mocked repositories
- âœ… Integration tests pass

**Risk Mitigation:**
```python
# Phase 2a: Create repository alongside existing code
class EmployeeRepository:
    def find_by_id(self, id): ...

# Phase 2b: Service delegates to both (validation phase)
class EmployeeService:
    def get_employee(self, id):
        # Get from both old and new approach
        old_result = self._get_employee_old(id)
        new_result = self.employee_repo.find_by_id(id)
        assert old_result == new_result  # Validation
        return new_result

# Phase 2c: Remove old approach once validated
class EmployeeService:
    def get_employee(self, id):
        return self.employee_repo.find_by_id(id)
```

**Rollback Plan:**
- Repositories are additive until Step 4
- Services can use old approach if repository issues found
- No schema changes = data safe

---

#### **Week 7-8: #245 Excel Field Mapping** ğŸŸ  HIGH - PARALLEL TO #241
**Why Now:** Enables #250, independent of other work

**Approach: Create Schema, Migrate Gradually**
```
Step 1 (Days 1-2): Create schema module
  â”œâ”€â”€ Create backend/config/excel_schema.py
  â”œâ”€â”€ Define FieldMapping dataclass
  â”œâ”€â”€ Define ExcelSchema with all fields
  â””â”€â”€ Unit tests for schema validation

Step 2 (Days 3-4): Migrate parser
  â”œâ”€â”€ Refactor excel_parser.py to use schema
  â”œâ”€â”€ Test with existing Excel files
  â””â”€â”€ Verify identical parsing results

Step 3 (Days 5-6): Migrate exporter
  â”œâ”€â”€ Refactor excel_exporter.py to use schema
  â”œâ”€â”€ Test exported files match original format
  â””â”€â”€ Verify round-trip (import â†’ export â†’ import)

Step 4 (Days 7-8): Migrate validator
  â”œâ”€â”€ Update data_validator.py to use schema
  â”œâ”€â”€ Remove all duplicate field definitions
  â””â”€â”€ Update tests
```

**Success Criteria:**
- âœ… Single source of truth for Excel mappings
- âœ… Parser and exporter use same schema
- âœ… Exported files identical to pre-refactoring
- âœ… All existing Excel files parse correctly

**Testing Strategy:**
```python
def test_round_trip_identical():
    """Ensure refactoring doesn't change behavior."""
    # Import existing file
    session_before = import_excel("test_data.xlsx")

    # Export to new file
    export_excel(session_before, "exported.xlsx")

    # Import exported file
    session_after = import_excel("exported.xlsx")

    # Should be identical
    assert session_before == session_after
```

---

### **Phase 3: Service Layer Decomposition (Weeks 9-12)**
*Break god classes into focused services*

#### **Week 9-10: #237 Split SessionManager** ğŸ”´ CRITICAL - DEPENDS ON #234, #241
**Why Now:** Repository pattern enables clean splits

**Approach: Strangler Fig - Create New, Delegate, Remove Old**
```
Step 1 (Days 1-2): Create new service classes (parallel to old)
  â”œâ”€â”€ Create SessionService (lifecycle only)
  â”œâ”€â”€ Create EmployeeService (CRUD only)
  â”œâ”€â”€ Create BoxOperationService (moves/swaps)
  â””â”€â”€ Create CalibrationService (calibration)

Step 2 (Days 3-4): Update SessionManager to delegate
  â”œâ”€â”€ SessionManager becomes facade
  â”œâ”€â”€ Old methods delegate to new services
  â”œâ”€â”€ Test: behavior unchanged
  â””â”€â”€ Deploy to dev

Step 3 (Days 5-7): Migrate API endpoints one by one
  â”œâ”€â”€ Update /sessions/* to use SessionService
  â”œâ”€â”€ Update /employees/* to use EmployeeService
  â”œâ”€â”€ Update /box-operations/* to use BoxOperationService
  â””â”€â”€ Test each before moving to next

Step 4 (Days 8-10): Remove SessionManager facade
  â”œâ”€â”€ Verify all API endpoints migrated
  â”œâ”€â”€ Delete SessionManager class
  â”œâ”€â”€ Update all tests
  â””â”€â”€ Celebrate ğŸ‰ (739 â†’ ~150 lines each!)
```

**Success Criteria:**
- âœ… SessionManager deleted
- âœ… 4 focused services averaging 150-250 lines each
- âœ… Each service has single responsibility
- âœ… All tests pass, no functionality lost

**Safety Checkpoints:**
```
Checkpoint 1 (after Step 2): Both approaches working
  - Can deploy SessionManager facade safely
  - Can rollback to monolithic if needed

Checkpoint 2 (after each API migration in Step 3):
  - Deploy to dev after each endpoint
  - Test thoroughly before next endpoint
  - Can rollback individual endpoints

Checkpoint 3 (before Step 4):
  - All endpoints using new services
  - Verify SessionManager has no real callers
  - Safe to delete
```

---

#### **Week 11: #252 Event Tracking Consolidation** ğŸŸ  HIGH - DEPENDS ON #234, #237
**Why Now:** SessionManager split provides clean slate

**Approach: Create Standalone Service**
```
Step 1 (Days 1-2): Create EventService
  â”œâ”€â”€ Create standalone EventService (no SessionManager dependency)
  â”œâ”€â”€ Create EventRepository
  â”œâ”€â”€ Unit tests with mocked repository
  â””â”€â”€ Integration tests with real DB

Step 2 (Days 3-4): Migrate event tracking calls
  â”œâ”€â”€ Update all services to inject EventService
  â”œâ”€â”€ Replace SessionManager.track_event() calls
  â”œâ”€â”€ Replace EventManager.log_event() calls
  â””â”€â”€ Test: events still tracked correctly

Step 3 (Day 5): Delete old event tracking
  â”œâ”€â”€ Remove event tracking from SessionManager (already deleted!)
  â”œâ”€â”€ Delete EventManager class
  â””â”€â”€ Verify no circular dependencies
```

**Success Criteria:**
- âœ… Standalone EventService with clear responsibility
- âœ… No circular dependencies
- âœ… All events tracked consistently
- âœ… EventManager deleted

---

#### **Week 12: #256 Complex Export Method** ğŸŸ¡ MEDIUM - PARALLEL
**Why Now:** Can work in parallel, low risk

**Approach: Composed Method Pattern**
```
Step 1 (Days 1-2): Extract helper methods
  â”œâ”€â”€ Extract _gather_session_data()
  â”œâ”€â”€ Extract _create_workbook()
  â”œâ”€â”€ Extract _add_header_row()
  â””â”€â”€ Keep main export_session() orchestrating

Step 2 (Days 3-4): Create ExcelStyler class
  â”œâ”€â”€ Extract all styling logic
  â”œâ”€â”€ Create backend/services/excel_styles.py
  â””â”€â”€ Unit tests for styling

Step 3 (Day 5): Refactor main method
  â”œâ”€â”€ Main method delegates to helpers
  â”œâ”€â”€ Each helper < 20 lines
  â””â”€â”€ Test: exports identical to before
```

**Success Criteria:**
- âœ… Main method < 20 lines (orchestration only)
- âœ… Helper methods < 20 lines each (focused logic)
- âœ… Exported files identical to before refactoring
- âœ… Cyclomatic complexity < 10 for all methods

**Testing:**
```python
def test_export_identical_before_and_after():
    """Ensure refactoring doesn't change output."""
    # Export with old monolithic method
    old_bytes = export_session_old("sess-1")

    # Export with refactored composed method
    new_bytes = export_session_new("sess-1")

    # Should be byte-for-byte identical
    assert old_bytes == new_bytes
```

---

### **Phase 4: Standards & Configuration (Weeks 13-16)**
*Polish with standards and configuration*

#### **Week 13-14: #253 Error Handling Standards** ğŸŸ¡ MEDIUM - PARALLEL
**Why Now:** Independent, can be done anytime

**Approach: Create Infrastructure, Migrate Gradually**
```
Step 1 (Days 1-2): Create exception infrastructure
  â”œâ”€â”€ Create backend/exceptions.py with hierarchy
  â”œâ”€â”€ Create backend/middleware/error_handler.py
  â”œâ”€â”€ Register middleware in FastAPI app
  â””â”€â”€ Tests for exception handling

Step 2 (Days 3-5): Migrate service layer
  â”œâ”€â”€ Replace return None with raise NotFoundError()
  â”œâ”€â”€ Replace error dicts with raise ValidationError()
  â”œâ”€â”€ Update service tests to expect exceptions
  â””â”€â”€ One service per day

Step 3 (Days 6-8): Migrate API layer
  â”œâ”€â”€ Remove try/catch blocks from endpoints
  â”œâ”€â”€ Remove manual HTTPException raises
  â”œâ”€â”€ Let middleware handle all errors
  â””â”€â”€ Test error responses match expected format

Step 4 (Days 9-10): Cleanup and documentation
  â”œâ”€â”€ Remove old error handling patterns
  â”œâ”€â”€ Add linting rules
  â””â”€â”€ Document error codes
```

**Success Criteria:**
- âœ… All errors use exception hierarchy
- âœ… Consistent JSON error format
- âœ… Proper HTTP status codes
- âœ… No return None or error dicts

---

#### **Week 15: #254 Configuration Management** ğŸŸ¡ MEDIUM - DEPENDS ON #255
**Why Now:** Constants already consolidated (#255 in Phase 1)

**Approach: Create Config, Extract Numbers, Migrate**
```
Step 1 (Days 1-2): Create configuration system
  â”œâ”€â”€ Create backend/config/business_rules.py
  â”œâ”€â”€ Create config/business_rules.yaml
  â”œâ”€â”€ Add validation logic
  â””â”€â”€ Tests for config loading

Step 2 (Days 3-4): Find all magic numbers
  â”œâ”€â”€ grep -rn "[0-9]\+\.[0-9]\+" backend/
  â”œâ”€â”€ Document each: what, why, where
  â””â”€â”€ Categorize: thresholds, limits, percentages

Step 3 (Days 4-5): Replace magic numbers
  â”œâ”€â”€ Add to configuration dataclasses
  â”œâ”€â”€ Replace literals with BusinessRules.*.value
  â””â”€â”€ Test: behavior unchanged
```

**Success Criteria:**
- âœ… Zero magic numbers in code
- âœ… All business rules in configuration
- âœ… YAML file documents all values
- âœ… Validation prevents invalid configs

---

#### **Week 16: #250 Column Schema Abstraction** ğŸŸ  HIGH - DEPENDS ON #245, #255
**Why Last:** Builds on Excel schema (#245) and constants (#255)

**Approach: Generate from Schema**
```
Step 1 (Days 1-2): Extend ExcelSchema
  â”œâ”€â”€ Add column metadata to schema
  â”œâ”€â”€ Add TypeScript type generation
  â””â”€â”€ Tests for schema completeness

Step 2 (Days 3-4): Replace hardcoded mappings
  â”œâ”€â”€ Replace column indices with schema lookups
  â”œâ”€â”€ Replace column names with schema values
  â””â”€â”€ Update API to use field enums

Step 3 (Day 5): Generate TypeScript types
  â”œâ”€â”€ Create type generation script
  â”œâ”€â”€ Generate frontend/src/types/employee.ts
  â”œâ”€â”€ Add CI check for sync
  â””â”€â”€ Document generation process
```

**Success Criteria:**
- âœ… Zero hardcoded column mappings
- âœ… TypeScript types auto-generated from Python
- âœ… CI enforces frontend/backend sync
- âœ… All existing code uses schema

---

## Risk Mitigation Strategies

### **Strategy 1: Feature Flags**
Enable/disable refactored code paths:

```python
# backend/config/feature_flags.py
class FeatureFlags:
    USE_DEPENDENCY_INJECTION = os.getenv("USE_DI", "true") == "true"
    USE_REPOSITORY_PATTERN = os.getenv("USE_REPOS", "true") == "true"
    USE_NEW_ERROR_HANDLING = os.getenv("USE_NEW_ERRORS", "true") == "true"

# Usage in code
if FeatureFlags.USE_REPOSITORY_PATTERN:
    employees = self.employee_repo.find_by_session(session_id)
else:
    employees = self._get_employees_old(session_id)  # Fallback
```

**Benefits:**
- Instant rollback via environment variable
- A/B testing in production
- Gradual rollout to users

### **Strategy 2: Parallel Run Validation**
Run old and new code, compare results:

```python
def get_employee_with_validation(employee_id: str):
    """Run both approaches and validate they match."""
    # Old approach
    old_result = _get_employee_old(employee_id)

    # New approach
    new_result = employee_repo.find_by_id(employee_id)

    # Validate they match
    if old_result != new_result:
        logger.error(
            "Discrepancy detected!",
            extra={"old": old_result, "new": new_result}
        )
        # Return old result (safe fallback)
        return old_result

    # Results match, use new approach
    return new_result
```

**Benefits:**
- Catches bugs before they affect users
- Builds confidence in refactoring
- Automatic fallback to old code

### **Strategy 3: Incremental Deployment**
Deploy in stages with monitoring:

```
Stage 1: Dev Environment (1-2 days)
  â”œâ”€â”€ Deploy refactored code
  â”œâ”€â”€ Run automated tests
  â”œâ”€â”€ Manual QA testing
  â””â”€â”€ Monitor error rates

Stage 2: Staging Environment (2-3 days)
  â”œâ”€â”€ Deploy to staging
  â”œâ”€â”€ Load testing
  â”œâ”€â”€ Integration testing
  â””â”€â”€ Monitor performance

Stage 3: Production Canary (1 week)
  â”œâ”€â”€ Deploy to 10% of users
  â”œâ”€â”€ Monitor metrics closely
  â”œâ”€â”€ Compare error rates to baseline
  â””â”€â”€ Rollback if issues detected

Stage 4: Full Production (1 week)
  â”œâ”€â”€ Gradual rollout to 100%
  â”œâ”€â”€ Monitor continuously
  â””â”€â”€ Remove feature flags once stable
```

### **Strategy 4: Comprehensive Testing**
Test at every level:

```
Unit Tests (per class)
  â”œâ”€â”€ Mock all dependencies
  â”œâ”€â”€ Test business logic isolated
  â”œâ”€â”€ Target: 90%+ coverage
  â””â”€â”€ Fast (< 1 second total)

Integration Tests (per layer)
  â”œâ”€â”€ Test with real database
  â”œâ”€â”€ Test repository queries
  â”œâ”€â”€ Target: All critical paths
  â””â”€â”€ Medium speed (< 10 seconds)

End-to-End Tests (per feature)
  â”œâ”€â”€ Test full API flows
  â”œâ”€â”€ Test UI â†’ API â†’ DB â†’ API â†’ UI
  â”œâ”€â”€ Target: Happy paths + error cases
  â””â”€â”€ Slow (< 2 minutes)

Regression Tests (before deployment)
  â”œâ”€â”€ Test all existing Excel files import correctly
  â”œâ”€â”€ Test all exports match pre-refactoring format
  â”œâ”€â”€ Test performance hasn't degraded
  â””â”€â”€ Compare error rates to baseline
```

### **Strategy 5: Monitoring & Observability**

```python
# Add structured logging to new code
logger.info(
    "Employee repository query",
    extra={
        "operation": "find_by_session",
        "session_id": session_id,
        "duration_ms": duration,
        "result_count": len(employees)
    }
)

# Monitor key metrics
- API response times (p50, p95, p99)
- Error rates by endpoint
- Database query performance
- Memory usage
- User error reports
```

**Alerts:**
- Response time > 2x baseline â†’ Investigate
- Error rate > 1% â†’ Rollback
- Memory usage > 80% â†’ Scale or optimize

---

## Testing Strategy

### **Regression Test Suite**
Ensure refactoring doesn't break functionality:

```python
# tests/regression/test_session_operations.py
class TestSessionOperationsRegression:
    """Regression tests to ensure refactoring doesn't break features."""

    def test_create_session_flow(self):
        """Test: Create session â†’ Add employees â†’ Move employees â†’ Export"""
        # 1. Create session
        session = client.post("/sessions", json={"name": "Test"})
        assert session.status_code == 201
        session_id = session.json()["id"]

        # 2. Add employees
        for i in range(10):
            emp = client.post(f"/sessions/{session_id}/employees", json={
                "name": f"Employee {i}",
                "employee_id": f"emp-{i}"
            })
            assert emp.status_code == 201

        # 3. Move employees
        move = client.post(f"/employees/emp-1/move", json={
            "target_box": "top_right"
        })
        assert move.status_code == 200

        # 4. Export
        export = client.get(f"/sessions/{session_id}/export")
        assert export.status_code == 200
        assert export.headers["content-type"] == "application/vnd.ms-excel"

    def test_excel_import_export_roundtrip(self):
        """Test: Import Excel â†’ Modify â†’ Export â†’ Import again â†’ Verify identical"""
        # Import test file
        with open("tests/fixtures/sample.xlsx", "rb") as f:
            import_resp = client.post("/import", files={"file": f})
        assert import_resp.status_code == 201
        session_id = import_resp.json()["session_id"]

        # Export to bytes
        export_resp = client.get(f"/sessions/{session_id}/export")
        exported_bytes = export_resp.content

        # Import exported file
        reimport_resp = client.post("/import", files={
            "file": ("exported.xlsx", exported_bytes)
        })
        assert reimport_resp.status_code == 201

        # Compare sessions (should be identical)
        original = client.get(f"/sessions/{session_id}").json()
        reimported_id = reimport_resp.json()["session_id"]
        reimported = client.get(f"/sessions/{reimported_id}").json()

        assert original["employees"] == reimported["employees"]
```

### **Performance Benchmarks**
Ensure refactoring doesn't degrade performance:

```python
# tests/performance/test_benchmarks.py
import pytest
from time import perf_counter

@pytest.mark.benchmark
def test_employee_query_performance(benchmark):
    """Benchmark: Query 100 employees should take < 100ms"""
    def query_employees():
        return employee_repo.find_by_session("sess-1")

    result = benchmark(query_employees)

    # Verify performance
    assert benchmark.stats.mean < 0.1  # < 100ms average
    assert len(result) == 100

@pytest.mark.benchmark
def test_excel_export_performance(benchmark):
    """Benchmark: Export 1000 employees should take < 5 seconds"""
    def export_large_session():
        return exporter.export_session("sess-large")

    result = benchmark(export_large_session)

    assert benchmark.stats.mean < 5.0  # < 5 seconds
```

---

## Rollback Procedures

### **Immediate Rollback (< 5 minutes)**
If critical issue detected in production:

```bash
# 1. Disable feature flag (instant rollback)
kubectl set env deployment/backend USE_REPOSITORY_PATTERN=false

# 2. Verify rollback
curl https://api.9boxer.com/health
# Should show: repository_pattern: false

# 3. Monitor error rates
# Should return to baseline within 1 minute
```

### **Partial Rollback (< 30 minutes)**
If specific feature problematic:

```bash
# 1. Revert specific commit
git revert <commit-hash>

# 2. Deploy to production
./scripts/deploy.sh --fast-track

# 3. Verify deployment
kubectl rollout status deployment/backend
```

### **Full Rollback (< 2 hours)**
If major issues require full reversion:

```bash
# 1. Rollback to previous release
kubectl rollout undo deployment/backend

# 2. Verify database schema unchanged
# (Our refactorings don't change schema, so data is safe)

# 3. Run smoke tests
pytest tests/smoke/

# 4. Monitor for 1 hour
# Ensure error rates and performance back to normal
```

---

## Success Metrics

Track these metrics to measure refactoring success:

### **Code Quality Metrics**

| Metric | Before | Target | Measurement |
|--------|--------|--------|-------------|
| **Average Service Size** | 739 lines | < 250 lines | `tokei backend/services/` |
| **Cyclomatic Complexity** | >15 (SessionManager) | < 10 | `radon cc backend/` |
| **Test Coverage** | 75% | > 90% | `pytest --cov` |
| **Code Duplication** | 15% | < 5% | `pylint --duplicate-code` |
| **Magic Numbers** | 47 occurrences | 0 | `grep -r "\b[0-9]\{2,\}\b" backend/` |

### **Maintainability Metrics**

| Metric | Before | Target | Measurement |
|--------|--------|--------|-------------|
| **Time to Add Feature** | 4 hours | < 2 hours | Track next 5 features |
| **Bug Fix Time** | 3 hours avg | < 1 hour avg | Track next 10 bugs |
| **Onboarding Time** | 2 weeks | < 1 week | Survey new developers |
| **Code Review Time** | 2 hours avg | < 1 hour avg | Track next 20 PRs |

### **System Health Metrics**

| Metric | Baseline | Threshold | Action if Exceeded |
|--------|----------|-----------|-------------------|
| **API Response Time (p95)** | 200ms | > 300ms | Investigate performance |
| **Error Rate** | 0.5% | > 1% | Rollback immediately |
| **Memory Usage** | 512MB | > 800MB | Optimize or scale |
| **Test Execution Time** | 45s | > 60s | Parallelize or optimize |

### **Business Metrics**

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Zero Downtime** | 100% | Track deployment windows |
| **Zero Data Loss** | 100% | Verify post-deployment |
| **User-Reported Bugs** | < 2 per week | Track support tickets |
| **Developer Satisfaction** | > 8/10 | Quarterly survey |

---

## Communication Plan

### **Stakeholder Updates**

**Weekly Progress Reports** (every Friday)
- Completed work
- Risks identified
- Blockers encountered
- Next week's plan

**Demo Sessions** (end of each phase)
- Show refactored code
- Explain benefits
- Discuss any concerns
- Gather feedback

**Incident Reports** (if rollback needed)
- What went wrong
- Why it happened
- How we fixed it
- How we'll prevent recurrence

### **Team Coordination**

**Daily Standups**
- What refactoring task working on
- Any dependencies needed from other devs
- Any blockers

**PR Review Protocol**
- Refactoring PRs get priority review (< 4 hours)
- Require 2 approvals for critical phases
- Include before/after metrics in PR description

**Pair Programming**
- Complex refactorings done in pairs
- Knowledge sharing sessions after each phase

---

## Contingency Planning

### **What If: Timeline Slips?**

**Option 1: Descope Non-Critical Issues**
- Keep: #234, #237, #241 (critical infrastructure)
- Defer: #256, #253, #254 (can be done later)

**Option 2: Extend Timeline**
- Add 2-4 weeks buffer
- Maintain quality over speed

**Option 3: Bring in Help**
- Pair senior devs with refactoring tasks
- External code review/consultation

### **What If: Major Bug Found Mid-Refactoring?**

**Response Protocol:**
1. **Assess Severity**: Critical (rollback) vs Non-critical (fix forward)
2. **Pause Refactoring**: Fix bug first, resume after
3. **Root Cause Analysis**: Why did refactoring introduce bug?
4. **Add Tests**: Ensure regression doesn't happen again
5. **Resume Refactoring**: With lessons learned

### **What If: Resource Constraints?**

**Prioritization:**
1. Complete Phase 1 (foundations) - mandatory
2. Complete Phase 2 (data layer) - highly recommended
3. Complete Phase 3 (service decomposition) - recommended
4. Defer Phase 4 (standards) to next quarter if needed

---

## Post-Refactoring

### **Week 17: Stabilization**
- Monitor production metrics
- Fix any issues found
- Remove feature flags
- Update documentation

### **Week 18: Retrospective**
- What went well?
- What could be improved?
- Lessons learned document
- Share knowledge with team

### **Week 19+: Maintenance**
- Add linting rules to prevent regressions
- Update onboarding docs
- Add architectural guidelines
- Plan next refactoring iteration

---

## Conclusion

This refactoring plan balances **safety** and **progress**:

- âœ… **Incremental**: Each phase is independently valuable
- âœ… **Safe**: Feature flags and parallel run enable rollback
- âœ… **Testable**: Comprehensive testing at every level
- âœ… **Monitored**: Metrics track success and catch issues early
- âœ… **Pragmatic**: Can descope or extend if needed

**Estimated ROI:**
- **Upfront Cost**: 12-16 weeks of focused refactoring
- **Long-term Benefit**: 50%+ reduction in maintenance time
- **Risk**: Mitigated through incremental approach and rollback capability

The backend will emerge from this refactoring with:
- Clean architecture following SOLID principles
- Testable, maintainable code
- Clear separation of concerns
- Documented standards and patterns

**Ready to begin? Start with Phase 1, Week 1: Dependency Injection! ğŸš€**
